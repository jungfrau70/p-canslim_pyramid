{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 카페 스크랩\n",
    "\n",
    "\n",
    "## 필요한 라이브러리 설치\n",
    "* 아나콘다 사용시 다음의 프롬프트 창을 열어 conda 명령어로 설치합니다.\n",
    "* pip 사용시 아래에 있는 명령어를 터미널로 설치합니다.\n",
    "<img src=\"https://i.imgur.com/Sar4gdw.jpg\">\n",
    "\n",
    "### Selenium\n",
    "* `conda install -c anaconda selenium`\n",
    "* [Selenium :: Anaconda Cloud](https://anaconda.org/anaconda/selenium)\n",
    "\n",
    "* pip 사용시 : `pip install selenium`\n",
    "\n",
    "### BeautifulSoup\n",
    "* `conda install -c anaconda beautifulsoup4`\n",
    "* [Beautifulsoup4 :: Anaconda Cloud](https://anaconda.org/anaconda/beautifulsoup4)\n",
    "\n",
    "* pip 사용시 : `pip install beautifulsoup4`\n",
    "\n",
    "### tqdm\n",
    "* `conda install -c conda-forge tqdm`\n",
    "* [tqdm/tqdm: A Fast, Extensible Progress Bar for Python and CLI](https://github.com/tqdm/tqdm)\n",
    "* `pip install tqdm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install pyperclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 100/100 [45:50<00:00, 27.50s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████| 100/100 [48:46<00:00, 29.26s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████| 100/100 [48:06<00:00, 28.87s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [49:21<00:00, 29.62s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [48:08<00:00, 28.88s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [49:02<00:00, 29.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [52:15<00:00, 31.35s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [53:28<00:00, 32.08s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [51:59<00:00, 31.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "# requests는 작은 웹브라우저로 웹사이트 내용을 가져온다.\n",
    "import requests\n",
    "# BeautifulSoup 을 통해 읽어 온 웹페이지를 파싱한다.\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# 크롤링 후 결과를 데이터프레임 형태로 보기 위해 불러온다.\n",
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pyperclip\n",
    "\n",
    "import time\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.headless = True\n",
    "options.add_argument(\"window-size=1920x1080\") # 가상화면 크기\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36\")\n",
    "\n",
    "# 브라우저 기동\n",
    "browser = webdriver.Chrome(options=options)\n",
    "\n",
    "# 네이버 카페 로그인\n",
    "#클립보드에 input을 복사한 뒤\n",
    "#해당 내용을 actionChain을 이용해 로그인 폼에 붙여넣기\n",
    "def copy_input(xpath, input):\n",
    "    pyperclip.copy(input)\n",
    "    browser.find_element_by_xpath(xpath).click()\n",
    "    ActionChains(browser).key_down(Keys.CONTROL).send_keys('v').key_up(Keys.CONTROL).perform()\n",
    "    time.sleep(1)\n",
    "\n",
    "id = 'issac_jung'\n",
    "pw = '2020@Alpha'\n",
    "\n",
    "browser.get('https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com')\n",
    "browser.implicitly_wait(3)\n",
    "\n",
    "copy_input('//*[@id=\"id\"]', id)\n",
    "time.sleep(1)\n",
    "copy_input('//*[@id=\"pw\"]', pw)\n",
    "time.sleep(1)\n",
    "browser.find_element_by_xpath('//*[@id=\"frmNIDLogin\"]/fieldset/input').click()\n",
    "\n",
    "keywords = ['외식', '식사', '메뉴', '식당', '레스토랑', '가성비', '트렌드', '배달', '맛집', '비대면']\n",
    "keywords = ['식사', '메뉴', '식당', '레스토랑', '가성비', '트렌드', '배달', '맛집', '비대면']\n",
    "\n",
    "# print(keywords)\n",
    "# keywords = [ '1인 외식']\n",
    "\n",
    "# 페이지 로딩 대기 시간(초)\n",
    "interval = 3\n",
    "\n",
    "# 다음뉴스 키워드 검색 Main 호출\n",
    "pnum = 1000 # 1500개 news 가져오기, 15 페이지 (페이지당 10개 )\n",
    "\n",
    "# 키워드 별 URL 파일 읽어 blog post 가져오기\n",
    "for keyword in keywords:\n",
    "\n",
    "    # 파일에서 읽어 원하는 모양으로 변환 (모두 List 형)으로 변환\n",
    "#     urls_filename = \"./urls/\" + \"naver-cafe_\" + keyword.replace(\" \",\"\") + \".csv\"\n",
    "#     df_postURLs = pd.read_csv(urls_filename, header=1)\n",
    "#     urls = df_postURLs.values.tolist()\n",
    "\n",
    "    titles = []\n",
    "    dates = []\n",
    "    counts = []\n",
    "    contents = []\n",
    "    post_df = pd.DataFrame(columns=(\"title\", \"date\", \"count\", \"content\"))\n",
    "    \n",
    "    start_date = \"2019.07.01\"\n",
    "    end_date = \"2020.06.30\"\n",
    "    \n",
    "    pages = (pnum // 10 ) + 1\n",
    "    for page in trange(1, pages):  # 150 번 페이지\n",
    "\n",
    "        url = f'https://m.cafe.naver.com/SectionArticleSearch.nhn?page={page}&sortBy=0&query={keyword}&period=[\"2019.07.01\",\"2020.06.30\"]'\n",
    "#         url = f'https://section.cafe.naver.com/cafe-home/search/articles?query={keyword}\n",
    "\n",
    "        for i in range(0, 10):\n",
    "            try:\n",
    "                browser.get(url)\n",
    "                time.sleep(1)\n",
    "                browser.find_elements_by_css_selector(\"strong.tit\")[i].click()\n",
    "                time.sleep(1)\n",
    "                          \n",
    "                post_soup = bs(browser.page_source, 'html.parser')  # 웹 페이지 파싱\n",
    "\n",
    "                title = post_soup.find('h2', attrs={\"class\":\"tit\"}).get_text().strip()\n",
    "                date = post_soup.find('span', attrs={\"class\":\"date font_l\"}).get_text().strip()\n",
    "                count = post_soup.find('span', attrs={\"class\":\"no font_l\"}).get_text().strip()\n",
    "#                 content = post_soup.find('div', attrs={\"class\":\"se-main-container\"}).get_text().strip()\n",
    "                content = post_soup.find('div', attrs={\"class\":\"post_cont font_zoom1\"}).get_text().strip()\n",
    "\n",
    "                titles.append(title)\n",
    "                dates.append(date)\n",
    "                counts.append(count)\n",
    "                contents.append(content)\n",
    "            \n",
    "            except:\n",
    "#                 print(\"오류 발생\")\n",
    "                continue\n",
    "\n",
    "    post_df = pd.DataFrame({\"title\": titles, \"date\": dates, \"count\": counts, \"content\": contents})\n",
    "#     print(post_df)\n",
    "\n",
    "    # 파일 쓰기\n",
    "    output_filename = \"./scraps/\" + \"naver-cafe-scrapped_\" + keyword.replace(\" \",\"\") + \".csv\"\n",
    "#     print(output_filename)\n",
    "\n",
    "    post_df.to_csv(output_filename, date_format='%Y%m%d', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
